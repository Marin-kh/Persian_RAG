{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e75e667d5a8445ae8905b999ae188326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5251ba9dc3a4523881f138f67a50c12",
              "IPY_MODEL_da62770cf09b4e1c9310f533ec54ec8c",
              "IPY_MODEL_9187119b37954c1296062510c793187d"
            ],
            "layout": "IPY_MODEL_27c2ce8779814d44bfa5f4af33f446a6"
          }
        },
        "b5251ba9dc3a4523881f138f67a50c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82725d5005c4d1296def28655ed8df3",
            "placeholder": "​",
            "style": "IPY_MODEL_00317937fc0645399cfb1ca64bf4fb4a",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
          }
        },
        "da62770cf09b4e1c9310f533ec54ec8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4cc6b2837d40b4ae2a674174445c81",
            "max": 52741,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b41c978d0cf48eea75c87af14ffb852",
            "value": 52741
          }
        },
        "9187119b37954c1296062510c793187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3d819260b345b8a6896b8a5279de9a",
            "placeholder": "​",
            "style": "IPY_MODEL_14d83a24258246249e0f083b267ac6e1",
            "value": " 426k/? [00:00&lt;00:00, 19.8MB/s]"
          }
        },
        "27c2ce8779814d44bfa5f4af33f446a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82725d5005c4d1296def28655ed8df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00317937fc0645399cfb1ca64bf4fb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e4cc6b2837d40b4ae2a674174445c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b41c978d0cf48eea75c87af14ffb852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b3d819260b345b8a6896b8a5279de9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d83a24258246249e0f083b267ac6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a3838c6f8546bcab2fdf3d0dc7c105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e15ae80d21c14a3a8e992edd08a75a95",
              "IPY_MODEL_5f20b41b295d46628c955d24e0ea4c33",
              "IPY_MODEL_f1346f52b0b14c2794c73d3f087ae0ad"
            ],
            "layout": "IPY_MODEL_c918f3bcab40485d9741ece6dfd71228"
          }
        },
        "e15ae80d21c14a3a8e992edd08a75a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63b99e3e2b945a2aa4eddd3b42026d2",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb89a826f08408ea7386e384f16c90f",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.10.0/models/default.zip: 100%"
          }
        },
        "5f20b41b295d46628c955d24e0ea4c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3deb66503d343ec8dbf6ddab19306cb",
            "max": 334977676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a971851e29a42bea65e45df03de2a5c",
            "value": 334977676
          }
        },
        "f1346f52b0b14c2794c73d3f087ae0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1beb57a4a98542ef9831beca2883b3e4",
            "placeholder": "​",
            "style": "IPY_MODEL_36b8c02384af4c84816e0f88246600f0",
            "value": " 335M/335M [00:02&lt;00:00, 85.1MB/s]"
          }
        },
        "c918f3bcab40485d9741ece6dfd71228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63b99e3e2b945a2aa4eddd3b42026d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb89a826f08408ea7386e384f16c90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3deb66503d343ec8dbf6ddab19306cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a971851e29a42bea65e45df03de2a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1beb57a4a98542ef9831beca2883b3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b8c02384af4c84816e0f88246600f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "359a786bf70742c79f1c4572fe649740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c264576e6142bda480db3e06e0ebe4",
              "IPY_MODEL_7ad3e5b677fb45169252219816fb70cd",
              "IPY_MODEL_323f2d054b7f4af784f839bc2321c240"
            ],
            "layout": "IPY_MODEL_6a64cf5f8bf640ab981dd285c23b03e4"
          }
        },
        "d3c264576e6142bda480db3e06e0ebe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05c89ab7ec14638a79a0cbdc9b7da90",
            "placeholder": "​",
            "style": "IPY_MODEL_eb21a12291024e44960ef4d013adff4e",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
          }
        },
        "7ad3e5b677fb45169252219816fb70cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e69fe941c8a4af7bfa31c4727e33747",
            "max": 52741,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4b5b24b1864484485f74733bddbad8e",
            "value": 52741
          }
        },
        "323f2d054b7f4af784f839bc2321c240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e3d519b3b644b8b1b4920512f2e571",
            "placeholder": "​",
            "style": "IPY_MODEL_1d1728d49eb4407cb3813ad4f18762bf",
            "value": " 426k/? [00:00&lt;00:00, 14.0MB/s]"
          }
        },
        "6a64cf5f8bf640ab981dd285c23b03e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05c89ab7ec14638a79a0cbdc9b7da90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb21a12291024e44960ef4d013adff4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e69fe941c8a4af7bfa31c4727e33747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b5b24b1864484485f74733bddbad8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65e3d519b3b644b8b1b4920512f2e571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1728d49eb4407cb3813ad4f18762bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marin-kh/Persian_RAG/blob/main/Persian_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVPZcCqTiMTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e05d52-2d1b-4965-ac62-4a8ee97ab7f5",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n",
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from rake_nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.67.1)\n",
            "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: rake_nltk\n",
            "Successfully installed rake_nltk-1.0.6\n",
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.2.1)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53893 sha256=6906acdb6d7b41720daa15c01fad0c0c9c7ab45a5d75f7cbf60eb4fc4bb16c90\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (5.29.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m770.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed emoji-2.14.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stanza-1.10.1\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.24.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.56)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.4.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.24.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.24.0 langchain_groq-0.3.2\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.56)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.4.0)\n",
            "Downloading langgraph-0.4.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.1/151.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, tiktoken, langgraph-sdk, langchain_core, langgraph-checkpoint, langchain_openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed langchain_core-0.3.58 langchain_openai-0.3.16 langgraph-0.4.2 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 ormsgpack-1.9.1 tiktoken-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "!pip install rake_nltk\n",
        "!pip install docx\n",
        "!pip install stanza\n",
        "!pip install gradio\n",
        "!pip install langchain_groq\n",
        "!pip install langgraph langchain_openai langchain_core\n",
        "!pip install langchain_community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "collapsed": true,
        "id": "LXhPxzxMb4kH",
        "outputId": "7736e42a-430d-40ec-eac0-576cbb9f631d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from hazm) (0.9.2)\n",
            "Requirement already satisfied: flashtext<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from hazm) (2.7)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from hazm) (4.3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from hazm) (3.9.1)\n",
            "Collecting numpy==1.24.3 (from hazm)\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.11/dist-packages (from hazm) (0.9.11)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from hazm) (1.6.1)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (75.2.0)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.17.2)\n",
            "Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.23 requires numpy>=1.26.2; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d00b3aed0edb4760bd5bd2beac949610"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from hazm import stopwords_list, Normalizer, WordTokenizer, SentenceTokenizer, Stemmer, Lemmatizer, sent_tokenize, word_tokenize\n",
        "import docx\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import requests\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import openai\n",
        "import nltk\n",
        "from rake_nltk import Rake\n",
        "from google.colab import drive\n",
        "import stanza\n",
        "from collections import defaultdict\n",
        "from openai import OpenAI\n",
        "from typing import Optional, TypedDict, Annotated\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_core.messages import SystemMessage, AnyMessage, HumanMessage, ToolMessage\n",
        "import operator\n",
        "import gradio as gr\n",
        "import json"
      ],
      "metadata": {
        "id": "T50h_ArvJ3Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download('fa')\n",
        "nlp = stanza.Pipeline('fa')"
      ],
      "metadata": {
        "id": "AZWv4d3mp2Ta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584,
          "referenced_widgets": [
            "e75e667d5a8445ae8905b999ae188326",
            "b5251ba9dc3a4523881f138f67a50c12",
            "da62770cf09b4e1c9310f533ec54ec8c",
            "9187119b37954c1296062510c793187d",
            "27c2ce8779814d44bfa5f4af33f446a6",
            "b82725d5005c4d1296def28655ed8df3",
            "00317937fc0645399cfb1ca64bf4fb4a",
            "4e4cc6b2837d40b4ae2a674174445c81",
            "8b41c978d0cf48eea75c87af14ffb852",
            "5b3d819260b345b8a6896b8a5279de9a",
            "14d83a24258246249e0f083b267ac6e1",
            "06a3838c6f8546bcab2fdf3d0dc7c105",
            "e15ae80d21c14a3a8e992edd08a75a95",
            "5f20b41b295d46628c955d24e0ea4c33",
            "f1346f52b0b14c2794c73d3f087ae0ad",
            "c918f3bcab40485d9741ece6dfd71228",
            "f63b99e3e2b945a2aa4eddd3b42026d2",
            "cfb89a826f08408ea7386e384f16c90f",
            "e3deb66503d343ec8dbf6ddab19306cb",
            "3a971851e29a42bea65e45df03de2a5c",
            "1beb57a4a98542ef9831beca2883b3e4",
            "36b8c02384af4c84816e0f88246600f0",
            "359a786bf70742c79f1c4572fe649740",
            "d3c264576e6142bda480db3e06e0ebe4",
            "7ad3e5b677fb45169252219816fb70cd",
            "323f2d054b7f4af784f839bc2321c240",
            "6a64cf5f8bf640ab981dd285c23b03e4",
            "d05c89ab7ec14638a79a0cbdc9b7da90",
            "eb21a12291024e44960ef4d013adff4e",
            "9e69fe941c8a4af7bfa31c4727e33747",
            "d4b5b24b1864484485f74733bddbad8e",
            "65e3d519b3b644b8b1b4920512f2e571",
            "1d1728d49eb4407cb3813ad4f18762bf"
          ]
        },
        "collapsed": true,
        "outputId": "2a187cc0-899c-4ed1-f19e-d84e6449fff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e75e667d5a8445ae8905b999ae188326"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: fa (Persian) ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.10.0/models/default.zip:   0%|          | …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a3838c6f8546bcab2fdf3d0dc7c105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/fa/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "359a786bf70742c79f1c4572fe649740"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Loading these models for language: fa (Persian):\n",
            "==============================\n",
            "| Processor | Package        |\n",
            "------------------------------\n",
            "| tokenize  | perdt          |\n",
            "| mwt       | perdt          |\n",
            "| pos       | perdt_charlm   |\n",
            "| lemma     | perdt_nocharlm |\n",
            "| depparse  | perdt_charlm   |\n",
            "| ner       | arman          |\n",
            "==============================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PersianRAKE(Rake):\n",
        "    def _tokenize_text_to_sentences(self, text: str):\n",
        "        return sent_tokenize(text)\n",
        "\n",
        "    def _tokenize_sentence_to_words(self, sentence: str):\n",
        "        return word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "waRPUyQUJ5jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_from_docx(doc):\n",
        "    fullText=''\n",
        "    for pra in doc.paragraphs:\n",
        "        fullText+=pra.text+' '\n",
        "\n",
        "    return fullText\n",
        "\n",
        "def split_into_overlapping_chunks(sentences, max_chunk_size=1000, overlap_size=200):\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_chunk_size = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_length = len(sentence)\n",
        "\n",
        "        if current_chunk_size + sentence_length > max_chunk_size and current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "            overlap_buffer = current_chunk[-overlap_size:].strip() if current_chunk else \"\"\n",
        "            current_chunk = overlap_buffer + \" \"\n",
        "            current_chunk_size = len(overlap_buffer) + 1\n",
        "\n",
        "        current_chunk += sentence + \" \"\n",
        "        current_chunk_size += sentence_length + 1\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def preprocess_text_1(text):\n",
        "    # text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'( +)', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_text_2(text):\n",
        "    text = re.sub('(\\(.*?\\))|(\\[.*?\\])', '', str(text))\n",
        "    text = re.sub(r'( +)', ' ', str(text))\n",
        "\n",
        "    word_tokenizer = WordTokenizer()\n",
        "    words = word_tokenizer.tokenize(text)\n",
        "\n",
        "    stopwords = stopwords_list()\n",
        "    filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "    lemmatizer = Lemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "\n",
        "def check_spelling(main_text):\n",
        "    endpoint = \"https://api.languagetool.org/v2/check\"\n",
        "\n",
        "    data = {\n",
        "        \"text\": main_text,\n",
        "        \"language\": \"en-US\",\n",
        "    }\n",
        "\n",
        "    response = requests.post(endpoint, data=data)\n",
        "    json_response = response.json()\n",
        "\n",
        "    updated_text = main_text\n",
        "\n",
        "    for match in json_response.get(\"matches\", []):\n",
        "        replacement = match[\"replacements\"][0][\"value\"] if match[\"replacements\"] else \"\"\n",
        "\n",
        "        offset = match[\"offset\"]\n",
        "        length = match[\"length\"]\n",
        "\n",
        "        updated_text = updated_text.replace(main_text[offset:offset+length], replacement)\n",
        "\n",
        "    print(\"Original Query: \", main_text)\n",
        "    print(\"Spell-checked Query: \", updated_text)\n",
        "    return updated_text\n",
        "\n",
        "def phrase_search(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    phrases = []\n",
        "    for sent in doc.sentences:\n",
        "        for word in sent.words:\n",
        "            if word.upos in ['NOUN', 'ADJ']:\n",
        "                phrase = word.text\n",
        "                for other_word in sent.words:\n",
        "                    if other_word.head == word.id and other_word.upos in ['NOUN', 'ADJ']:\n",
        "                        phrase += \" \" + other_word.text\n",
        "                if \" \" in phrase:\n",
        "                    phrases.append(phrase)\n",
        "    return phrases\n",
        "\n",
        "def english_to_persian_number(number_str):\n",
        "    english_to_persian = {\n",
        "        \"0\": \"۰\",\n",
        "        \"1\": \"۱\",\n",
        "        \"2\": \"۲\",\n",
        "        \"3\": \"۳\",\n",
        "        \"4\": \"۴\",\n",
        "        \"5\": \"۵\",\n",
        "        \"6\": \"۶\",\n",
        "        \"7\": \"۷\",\n",
        "        \"8\": \"۸\",\n",
        "        \"9\": \"۹\",\n",
        "    }\n",
        "    persian_number = \"\".join([english_to_persian[digit] for digit in number_str])\n",
        "    return persian_number\n",
        "\n",
        "def persian_words_to_number(sentence):\n",
        "    word_to_number = {\n",
        "        \"صفر\": 0,\n",
        "        \"یک\": 1,\n",
        "        \"دو\": 2,\n",
        "        \"سه\": 3,\n",
        "        \"چهار\": 4,\n",
        "        \"پنج\": 5,\n",
        "        \"شش\": 6,\n",
        "        \"هفت\": 7,\n",
        "        \"هشت\": 8,\n",
        "        \"نه\": 9,\n",
        "        \"ده\": 10,\n",
        "        \"یازده\": 11,\n",
        "        \"دوازده\": 12,\n",
        "        \"سیزده\": 13,\n",
        "        \"چهارده\": 14,\n",
        "        \"پانزده\": 15,\n",
        "        \"شانزده\": 16,\n",
        "        \"هفده\": 17,\n",
        "        \"هجده\": 18,\n",
        "        \"نوزده\": 19,\n",
        "        \"بیست\": 20,\n",
        "        \"سی\": 30,\n",
        "        \"چهل\": 40,\n",
        "        \"پنجاه\": 50,\n",
        "        \"شصت\": 60,\n",
        "        \"هفتاد\": 70,\n",
        "        \"هشتاد\": 80,\n",
        "        \"نود\": 90,\n",
        "        \"صد\": 100,\n",
        "        \"یکصد\": 100,\n",
        "        \"دویست\": 200,\n",
        "        \"سیصد\": 300,\n",
        "        \"چهارصد\": 400,\n",
        "        \"پانصد\": 500,\n",
        "        \"ششصد\": 600,\n",
        "        \"هفتصد\": 700,\n",
        "        \"هشتصد\": 800,\n",
        "        \"نهصد\": 900,\n",
        "        \"هزار\": 1000,\n",
        "    }\n",
        "    words = sentence.split(' ')\n",
        "\n",
        "    result = []\n",
        "    temp_number_words = []\n",
        "    current_number = 0\n",
        "\n",
        "    for word in words:\n",
        "        if word[-1:]=='م' and (word[:-1] in word_to_number):\n",
        "            word = word[:-1]\n",
        "        if word in word_to_number:\n",
        "            temp_number_words.append(word)\n",
        "            current_number += word_to_number[word]\n",
        "        else:\n",
        "            if temp_number_words:\n",
        "                english_number_str = str(current_number)\n",
        "                persian_number_str = english_to_persian_number(english_number_str)\n",
        "                result.append(persian_number_str)\n",
        "                temp_number_words = []\n",
        "                current_number = 0\n",
        "            result.append(word)\n",
        "\n",
        "    if temp_number_words:\n",
        "        english_number_str = str(current_number)\n",
        "        persian_number_str = english_to_persian_number(english_number_str)\n",
        "        result.append(persian_number_str)\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "def preprocess_phrases(text, phrases):\n",
        "    for phrase in phrases:\n",
        "        text = text.replace(phrase, phrase.replace(\" \", \"_\"))\n",
        "    return text\n",
        "\n",
        "def extract_persian_numbers(text):\n",
        "    persian_digits = \"۰۱۲۳۴۵۶۷۸۹\"\n",
        "    return re.findall(f\"[{persian_digits}]+\", text)\n",
        "\n",
        "def calculate_cosine_similarity(docs, phrase):\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
        "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "    phrase_vector = vectorizer.transform(phrase)\n",
        "    return cosine_similarity(phrase_vector, tfidf_matrix)\n",
        "\n",
        "def calculate_tf(document_numbers):\n",
        "    tf = []\n",
        "    for doc in document_numbers:\n",
        "        tf_dict = defaultdict(int)\n",
        "        for num in doc:\n",
        "            tf_dict[num] += 1\n",
        "        tf.append(tf_dict)\n",
        "    return tf\n",
        "\n",
        "def calculate_idf(document_numbers, numbers):\n",
        "    idf = {}\n",
        "    total_docs = len(document_numbers)\n",
        "    for num in numbers:\n",
        "        doc_count = sum(1 for doc in document_numbers if num in doc)\n",
        "        idf[num] = np.log((total_docs + 1) / (doc_count + 1)) + 1\n",
        "    return idf\n",
        "\n",
        "def calculate_tf_idf(document_numbers, numbers):\n",
        "    tf = calculate_tf(document_numbers)\n",
        "    idf = calculate_idf(document_numbers, numbers)\n",
        "    tf_idf = []\n",
        "    for doc_tf in tf:\n",
        "        doc_tf_idf = {}\n",
        "        for num, freq in doc_tf.items():\n",
        "            if num in idf:\n",
        "                doc_tf_idf[num] = freq * idf[num]\n",
        "        tf_idf.append(doc_tf_idf)\n",
        "    return tf_idf\n",
        "\n",
        "def get_city_link_by_name(persian_name: str):\n",
        "    try:\n",
        "        result = df_cities[df_cities['name'] == persian_name]['name_en']\n",
        "\n",
        "        if not result.empty:\n",
        "            return result.iloc[0]\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        return None"
      ],
      "metadata": {
        "id": "pDf4OEtAJ7n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading The Main Document\n",
        "drive.mount('/content/drive')\n",
        "document = read_from_docx(docx.Document(\"/content/drive/My Drive/delta.docx\"))\n",
        "df_api = pd.read_csv('/content/drive/My Drive/api_key.csv')\n",
        "df_cities = pd.read_csv('/content/drive/My Drive/cities_per_en.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W91Qf-pzKAOC",
        "outputId": "8fef9a05-621f-43a2-f7ca-0e667c9ad52a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    api_key=df_api.loc[2, 'api_key'],\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "eVZKdar0X8Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking The Document\n",
        "normalizer = Normalizer()\n",
        "normalized_text = normalizer.normalize(document)\n",
        "\n",
        "sentence_tokenizer = SentenceTokenizer()\n",
        "sentences = sentence_tokenizer.tokenize(normalized_text)\n",
        "\n",
        "max_chunk_size = 1000\n",
        "overlap_size = 200\n",
        "chunks = split_into_overlapping_chunks(sentences, max_chunk_size, overlap_size)\n",
        "print(\"<Chunk 1>\")\n",
        "print(f\"Original Chunk:\\n{chunks[0]}\")\n",
        "\n",
        "# Preprocessing The Chunks\n",
        "preprocessed1_chunks = [preprocess_text_1(chunk) for chunk in chunks]\n",
        "\n",
        "preprocessed2_chunks = [preprocess_text_2(chunk) for chunk in preprocessed1_chunks]\n",
        "print(f\"Preprocessed Chunk:\\n{preprocessed2_chunks[0]}\")"
      ],
      "metadata": {
        "id": "cNTikfkxKCzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140d91d5-85c6-4a34-83c0-53cc497993f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Chunk 1>\n",
            "Original Chunk:\n",
            "املاک دلتا یکی از شرکت‌های برجسته در صنعت املاک و مستغلات است که در زمینه خرید، فروش، اجاره و مدیریت املاک فعالیت می‌کند. این شرکت با بهره‌گیری از تجربه و تخصص خود در این حوزه، به مشتریان خود خدمات متنوعی ارائه می‌دهد. در این مقاله به بررسی تاریخچه، خدمات، مزایا و چالش‌های املاک دلتا خواهیم پرداخت: تاریخچه دلتا املاک دلتا در سال ۱۳۵۶ تأسیس شد و از آن زمان تا به امروز به یکی از نام‌های معتبر در صنعت املاک و مستغلات تبدیل‌شده است. این شرکت با هدف ارائه خدمات با کیفیت و ساختارهای نوآورانه به مشتریان، فعالیت خود را آغاز کرد. با گذشت زمان، املاک دلتا توانسته است با بهره‌گیری از تیمی متخصص و استفاده از فناوری‌های پیشرفته، جایگاه خود را در بازار مستحکم کند. خدمات املاک دلتا به ارائه طیف گسترده‌ای از خدمات در حوزه املاک و مستغلات می‌پردازد که شامل موارد زیر است: خرید و فروش املاک: این شرکت به مشتریان خود کمک می‌کند تا املاک مناسب برای خرید یا فروش را پیدا کنند. خدمات مشاوره‌ای در زمینه ارزیابی قیمت، معرفی املاک مناسب و فرآیندهای قانونی خرید و فروش از جمله خدمات این بخش است.\n",
            "Preprocessed Chunk:\n",
            "املاک دلتا شرکت برجسته صنعت املاک مستغلات زمینه خرید فروش اجاره مدیریت املاک فعالیت میکند شرکت بهرهگیری تجربه تخصص حوزه مشتریان خدمات متنوع ارائه میدهد مقاله بررسی تاریخچه خدمات مزایا چالش املاک دلتا پرداخت#پرداز تاریخچه دلتا املاک دلتا سال ۱۳۵۶ تأسیس زمان امروز نام معتبر صنعت املاک مستغلات تبدیلشده شرکت هدف ارائه خدمات کیفیت ساختار نوآورانه مشتریان فعالیت آغاز گذشت#گذر زمان املاک دلتا توانست#توان بهرهگیری تیمی متخصص استفاده فناوری پیشرفته جایگاه بازار مستحکم خدمات املاک دلتا ارائه طیف گستردهای خدمات حوزه املاک مستغلات میپردازد موارد خرید فروش املاک شرکت مشتریان کمک میکند املاک خرید فروش خدمات مشاور زمینه ارزیابی قیمت معرفی املاک فرآیند قانونی خرید فروش جمله خدمات\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROPERTY_TYPE_MAPPING = {\n",
        "    \"زمین\": {\"url\": \"store\", \"display\": \"زمین\"},\n",
        "    \"آپارتمان موقعیت اداری\": {\"url\": \"OfficeLocationApartment\", \"display\": \"آپارتمان موقعیت اداری\"},\n",
        "    \"باغ\": {\"url\": \"garden\", \"display\": \"باغ\"},\n",
        "    \"باغچه\": {\"url\": \"garden\", \"display\": \"باغ\"},\n",
        "    \"تجاری\": {\"url\": \"commercial\", \"display\": \"تجاری\"},\n",
        "    \"مغازه\": {\"url\": \"commercial\", \"display\": \"مغازه\"},\n",
        "    \"آپارتمان\": {\"url\": \"apartment\", \"display\": \"آپارتمان\"}\n",
        "}\n",
        "\n",
        "def normalize_query(query: str) -> str:\n",
        "    \"\"\"Normalize user input to fix common typos.\"\"\"\n",
        "    query = query.replace(\"آجهي\", \"آگهی\").replace(\"تند\", \"تعداد\")\n",
        "    query = query.replace(\"\\u200c\", \" \")\n",
        "    return query.strip()\n",
        "\n",
        "def clean_tool_call(tool_call: dict) -> dict:\n",
        "    \"\"\"Clean and validate tool call data.\"\"\"\n",
        "    tool_name = tool_call.get(\"name\", \"\").strip()\n",
        "    tool_args = tool_call.get(\"args\", {})\n",
        "\n",
        "    if isinstance(tool_args, str):\n",
        "        try:\n",
        "            tool_args = json.loads(tool_args.replace(\"'\", \"\\\"\"))\n",
        "        except json.JSONDecodeError:\n",
        "            tool_args = {\"query\": tool_args} if tool_args else {}\n",
        "\n",
        "    if not isinstance(tool_args, dict):\n",
        "        tool_args = {\"query\": str(tool_args)}\n",
        "\n",
        "    if \"query\" in tool_args:\n",
        "        tool_args[\"query\"] = normalize_query(tool_args[\"query\"])\n",
        "\n",
        "    return {\"name\": tool_name, \"args\": tool_args}\n",
        "\n",
        "def parse_content_tool_call(content: str) -> Optional[dict]:\n",
        "    \"\"\"Parse a tool call from response.content if it matches the expected format.\"\"\"\n",
        "    pattern = r'<function=(\\w+)\\s*(\\{.*?\\})\\s*</function>'\n",
        "    match = re.match(pattern, content.strip())\n",
        "    if match:\n",
        "        tool_name = match.group(1)\n",
        "        try:\n",
        "            tool_args = json.loads(match.group(2))\n",
        "            return {\"name\": tool_name, \"args\": tool_args}\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def search_properties_func(min_meter: Optional[int] = None, max_meter: Optional[int] = None,\n",
        "                         min_price: Optional[int] = None, max_price: Optional[int] = None,\n",
        "                         city: Optional[str] = \"tehran\", elevator: Optional[bool] = None,\n",
        "                         property_type: Optional[str] = \"apartment\") -> str:\n",
        "    \"\"\"\n",
        "    جستجو بین املاک سایت با فیلتر شهر، متراژ، قیمت، آسانسور و نوع ملک.\n",
        "    \"\"\"\n",
        "    if city:\n",
        "        city_en = get_city_link_by_name(city)\n",
        "        city = city_en if city_en else \"tehran\"\n",
        "    else:\n",
        "        city = \"tehran\"\n",
        "\n",
        "    property_info = PROPERTY_TYPE_MAPPING.get(property_type, PROPERTY_TYPE_MAPPING[\"آپارتمان\"])\n",
        "    property_url = property_info[\"url\"]\n",
        "    property_display = property_info[\"display\"]\n",
        "\n",
        "    base_url = f\"https://deltadev.ir/{city}/buy/{property_url}\"\n",
        "\n",
        "    query_params = []\n",
        "    if min_meter is not None and max_meter is not None:\n",
        "        query_params.append(f\"meter={min_meter}-{max_meter}\")\n",
        "    elif min_meter is not None:\n",
        "        query_params.append(f\"meter={min_meter}-\")\n",
        "    elif max_meter is not None:\n",
        "        query_params.append(f\"meter=-{max_meter}\")\n",
        "\n",
        "    if min_price is not None and max_price is not None:\n",
        "        query_params.append(f\"price={min_price}-{max_price}\")\n",
        "    elif min_price is not None:\n",
        "        query_params.append(f\"price={min_price}-\")\n",
        "    elif max_price is not None:\n",
        "        query_params.append(f\"price=-{max_price}\")\n",
        "\n",
        "    if elevator:\n",
        "        query_params.append(\"features=elevator\")\n",
        "\n",
        "    query_string = \"?\" + \"&\".join(query_params) if query_params else \"\"\n",
        "    url = base_url + query_string\n",
        "\n",
        "    filters = []\n",
        "    if min_meter is not None and max_meter is not None:\n",
        "        filters.append(f\"{min_meter} تا {max_meter} متر\")\n",
        "    elif min_meter is not None:\n",
        "        filters.append(f\"حداقل {min_meter} متر\")\n",
        "    elif max_meter is not None:\n",
        "        filters.append(f\"حداکثر {max_meter} متر\")\n",
        "\n",
        "    if min_price is not None and max_price is not None:\n",
        "        filters.append(f\"بین {min_price:,} تا {max_price:,} تومان\")\n",
        "    elif min_price is not None:\n",
        "        filters.append(f\"حداقل {min_price:,} تومان\")\n",
        "    elif max_price is not None:\n",
        "        filters.append(f\"حداکثر {max_price:,} تومان\")\n",
        "\n",
        "    if elevator:\n",
        "        filters.append(\"با آسانسور\")\n",
        "\n",
        "    if filters:\n",
        "        filters_str = \"، \".join(filters)\n",
        "        explanation = f\"با ویژگی‌هایی که گفتید ({filters_str})، می‌توانید بر روی این لینک کلیک کنید و ملک‌های مشابه را پیدا کنید: {url}\"\n",
        "    else:\n",
        "        explanation = f\"می‌توانید بر روی این لینک کلیک کنید و ملک‌های موجود را مشاهده کنید: {url}\"\n",
        "\n",
        "    return explanation\n",
        "\n",
        "search_properties = StructuredTool.from_function(\n",
        "    func=search_properties_func,\n",
        "    name=\"search_properties\",\n",
        "    description=\"جستجوی ملک برای خرید با فیلترهای شهر، متراژ، قیمت، آسانسور، و نوع ملک.\",\n",
        "    args_schema=None\n",
        ")\n",
        "\n",
        "def extract_text_func(query: str) -> str:\n",
        "    \"\"\"\n",
        "    استخراج و پردازش متن از داکیومنت با جستجوی هیبریدی و تولید پاسخ با LLM.\n",
        "    \"\"\"\n",
        "    query = check_spelling(query)\n",
        "    processed_query = preprocess_text_2(preprocess_text_1(query))\n",
        "    query_n = persian_words_to_number(processed_query)\n",
        "    phrases = phrase_search(query_n)\n",
        "    numbers = re.findall(r'\\d+', query_n)\n",
        "    numberic_chunks = [persian_words_to_number(chunk) for chunk in preprocessed2_chunks]\n",
        "\n",
        "    query_bonus = calculate_cosine_similarity(numberic_chunks, [query_n]).flatten()\n",
        "\n",
        "    document_numbers = [extract_persian_numbers(doc) for doc in numberic_chunks]\n",
        "    tf_idf_numbers = calculate_tf_idf(document_numbers, numbers)\n",
        "\n",
        "    number_bonus = np.zeros(len(numberic_chunks))\n",
        "    for i, doc_tf_idf in enumerate(tf_idf_numbers):\n",
        "        for num in numbers:\n",
        "            if num in doc_tf_idf:\n",
        "                number_bonus[i] += doc_tf_idf[num]\n",
        "    if np.max(number_bonus) > 0:\n",
        "        number_bonus = number_bonus / np.max(number_bonus)\n",
        "\n",
        "    preprocessed_docs = [preprocess_phrases(doc, phrases) for doc in numberic_chunks]\n",
        "    preprocessed_phrases = preprocess_phrases(query_n, phrases)\n",
        "\n",
        "    phrases_similarity = calculate_cosine_similarity(preprocessed_docs, [preprocessed_phrases])\n",
        "    phrases_bonus = np.max(phrases_similarity, axis=0)\n",
        "    if np.max(phrases_bonus) > 0:\n",
        "        phrases_bonus = phrases_bonus / np.max(phrases_bonus)\n",
        "\n",
        "    query_coef = 0.5\n",
        "    numbers_coef = 0.3\n",
        "    phrases_coef = 0.2\n",
        "\n",
        "    hybrid_scores = (query_bonus * query_coef) + (number_bonus * numbers_coef) + (phrases_bonus * phrases_coef)\n",
        "\n",
        "    top_k = 3\n",
        "    indices = np.argsort(-hybrid_scores)[:top_k]\n",
        "\n",
        "    top_3 = [chunks[idx] for idx in indices]\n",
        "    while len(top_3) < 3:\n",
        "        top_3.append(\"\")\n",
        "\n",
        "    llm = base_llm\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    {top_3[0]}\\n{top_3[1]}\\n{top_3[2]}\n",
        "    طبق اطلاعات بالا، به طور خلاصه به این سوال جواب بده: {query}\n",
        "    پاسخ باید به زبان پارسی باشد.\n",
        "    از کلمات «پاراگراف»، «متن»، «سند»، «داکیومنت»، «منبع»، یا «بالا» استفاده نکن.\n",
        "    اگر اطلاعات کافی برای پاسخ وجود نداشت، دقیقاً بگو: «نمی‌توانم جواب شما را بدهم» و هیچ توضیح اضافی نده.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        response_text = response.content.strip()\n",
        "    except Exception:\n",
        "        return \"نمی‌توانم جواب شما را بدهم\"\n",
        "\n",
        "    forbidden_words = [\"پاراگراف\", \"متن\", \"سند\", \"داکیومنت\", \"منبع\", \"بالا\"]\n",
        "    if any(word in response_text for word in forbidden_words) or (\"نمی‌توانم\" in response_text and response_text != \"نمی‌توانم جواب شما را بدهم\"):\n",
        "        return \"نمی‌توانم جواب شما را بدهم\"\n",
        "    return response_text\n",
        "\n",
        "extract_text = StructuredTool.from_function(\n",
        "    func=extract_text_func,\n",
        "    name=\"extract_text\",\n",
        "    description=\"استخراج اطلاعات از داکیومنت برای سوالات درباره املاک، سایت دلتا، یا کاربران سایت (مثل تعداد آگهی‌های مجاز، خطاهای سایت، یا اطلاعات عمومی).\",\n",
        "    args_schema=None\n",
        ")\n",
        "\n",
        "def connect_to_support_func(query: str) -> str:\n",
        "    \"\"\"\n",
        "    دادن شماره پشتیبانی سایت برای سوالاتی که در داکیومنت پاسخی ندارند.\n",
        "    \"\"\"\n",
        "    return f\" برای اطلاعات بیشتر، لطفاً با شماره پشتیبانی سایت دلتا (021-8686) تماس بگیرید.\"\n",
        "\n",
        "connect_to_support = StructuredTool.from_function(\n",
        "    func=connect_to_support_func,\n",
        "    name=\"connect_to_support\",\n",
        "    description=\"دادن شماره پشتیبانی سایت دلتا (021-8686) برای سوالات درباره املاک یا سایت که در داکیومنت پاسخی ندارند.\",\n",
        "    args_schema=None\n",
        ")\n",
        "\n",
        "def register_property_ad_func(query: str) -> str:\n",
        "    \"\"\"\n",
        "    راهنمایی کاربر برای ثبت آگهی فروش یا اجاره ملک در سایت دلتا.\n",
        "    \"\"\"\n",
        "    return \"\"\"برای فروش یا اجاره ملک، میتوانید آگهی خود را در سایت دلتا ثبت کنید. برای ثبت آگهی خود مراحل زیر را طی کنید:\n",
        "    ابتدا وارد حساب کاربری خود شوید یا ثبت نام کنید، سپس با انتخاب گزینه ثبت آگهی فروشی یا ثبت آگهی اجاره و تکمیل فرم مربوطه آگهی خود را در سایت دلتا ثبت کنید.\n",
        "    در هنگام ثبت ملک سعی کنید تا اطلاعات درخواستی ملک خود را به طور دقیق و کامل وارد نمایید تا اثربخشی آگهی شما افزایش یابد.\n",
        "    همچنین توجه داشته باشید که ثبت عکس برای آگهی امکان دیده شدن آن را تا 10 برابر افزایش می دهد.\n",
        "    \"\"\"\n",
        "\n",
        "register_property_ad = StructuredTool.from_function(\n",
        "    func=register_property_ad_func,\n",
        "    name=\"register_property_ad\",\n",
        "    description=\"راهنمایی برای ثبت آگهی فروش یا اجاره ملک وقتی کاربر صراحتاً قصد فروش یا اجاره دارد.\",\n",
        "    args_schema=None\n",
        ")\n",
        "\n",
        "llm = base_llm\n",
        "\n",
        "llm_with_tools = llm.bind_tools([search_properties, extract_text, connect_to_support, register_property_ad], parallel_tool_calls=False)\n",
        "\n",
        "def get_answer(user_input: str) -> str:\n",
        "    user_input = normalize_query(user_input)\n",
        "\n",
        "    sys_msg = SystemMessage(content=\"\"\"\n",
        "    تو یک مشاور املاک هستی که با چهار ابزار زیر کار می‌کنی:\n",
        "    - search_properties: برای وقتی که کاربر می‌خواهد ملکی بخرد (مثل 'یه آپارتمان در تهران بخرم'). فقط وقتی کاربر صراحتاً قصد خرید دارد و مشخصاتی مثل شهر یا نوع ملک داده، این ابزار را انتخاب کن.\n",
        "    - register_property_ad: برای وقتی که کاربر می‌خواهد ملکی را بفروشد یا اجاره دهد (مثل 'می‌خوام زمینم رو بفروشم' یا 'ملکم رو اجاره بدم'). فقط وقتی کاربر صراحتاً قصد فروش یا اجاره دارد، این ابزار را انتخاب کن.\n",
        "    - extract_text: برای سوالات درباره املاک، سایت دلتا، یا کاربران سایت (مثل 'چنتا آگهی تو ماه میشه گذاشت'، 'خوش آب و هوا ترین محله‌ها'، 'نحوه ثبت آگهی'، یا خطاهای سایت). اگر سوال درباره تعداد آگهی‌های مجاز، اطلاعات سایت، یا اطلاعات عمومی املاک است، این ابزار را انتخاب کن.\n",
        "    - connect_to_support: فقط وقتی سوال درباره املاک یا سایت دلتا است اما ابزار extract_text پاسخی پیدا نکرد (مثل 'چطور با مشاور صحبت کنم' بدون اطلاعات در داکیومنت).\n",
        "    اگر سوال کاربر به املاک یا سایت دلتا مربوط نیست (مثل 'قیمت دلار چنده؟')، هیچ ابزاری انتخاب نکن و فقط بگو: 'نمی‌توانم پاسخ این سوال را بدهم'.\n",
        "    ابزار مناسب را انتخاب کن و پاسخ را به پارسی بده. فقط یک ابزار را انتخاب کن و از توضیحات اضافی خودداری کن.\n",
        "    \"\"\")\n",
        "\n",
        "    messages = [sys_msg, HumanMessage(content=user_input)]\n",
        "\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = llm_with_tools.invoke(messages)\n",
        "            print(f\"LLM response (attempt {attempt + 1}): {response}\")  # Debugging\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"LLM invocation error (attempt {attempt + 1}): {str(e)}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                return \"نمی‌توانم پاسخ این سوال را بدهم. لطفاً دوباره امتحان کنید یا با پشتیبانی تماس بگیرید.\"\n",
        "            continue\n",
        "\n",
        "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
        "        tool_call = clean_tool_call(response.tool_calls[0])\n",
        "        tool_name = tool_call[\"name\"]\n",
        "        tool_args = tool_call[\"args\"]\n",
        "        print(f\"Executing tool: {tool_name} with args: {tool_args}\")  # Debugging\n",
        "\n",
        "        try:\n",
        "            if tool_name == \"search_properties\":\n",
        "                return search_properties.run(tool_input=tool_args)\n",
        "            elif tool_name == \"register_property_ad\":\n",
        "                return register_property_ad.run(tool_input=tool_args)\n",
        "            elif tool_name == \"extract_text\":\n",
        "                result = extract_text.run(tool_input=tool_args)\n",
        "                if result == \"نمی‌توانم جواب شما را بدهم\":\n",
        "                    if any(keyword in user_input.lower() for keyword in [\"ملک\", \"آگهی\", \"سایت\", \"دلتا\", \"محله\", \"مشاور\", \"آژانس\", \"خطا\", \"مجاز\", \"تعداد\"]):\n",
        "                        return connect_to_support.run(tool_input={\"query\": user_input})\n",
        "                return result\n",
        "            elif tool_name == \"connect_to_support\":\n",
        "                return connect_to_support.run(tool_input=tool_args)\n",
        "            return \"نمی‌توانم پاسخ این سوال را بدهم\"\n",
        "        except Exception as e:\n",
        "            print(f\"Tool execution error: {str(e)}\")\n",
        "            if any(keyword in user_input.lower() for keyword in [\"ملک\", \"آگهی\", \"سایت\", \"دلتا\", \"محله\", \"مشاور\", \"آژانس\", \"خطا\", \"مجاز\", \"تعداد\"]):\n",
        "                return connect_to_support.run(tool_input={\"query\": user_input})\n",
        "            return \"نمی‌توانم پاسخ این سوال را بدهم\"\n",
        "\n",
        "    if response.content:\n",
        "        parsed_tool_call = parse_content_tool_call(response.content)\n",
        "        if parsed_tool_call:\n",
        "            tool_call = clean_tool_call(parsed_tool_call)\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "            print(f\"Executing tool from content: {tool_name} with args: {tool_args}\")  # Debugging\n",
        "\n",
        "            try:\n",
        "                if tool_name == \"search_properties\":\n",
        "                    return search_properties.run(tool_input=tool_args)\n",
        "                elif tool_name == \"register_property_ad\":\n",
        "                    return register_property_ad.run(tool_input=tool_args)\n",
        "                elif tool_name == \"extract_text\":\n",
        "                    result = extract_text.run(tool_input=tool_args)\n",
        "                    if result == \"نمی‌توانم جواب شما را بدهم\":\n",
        "                        if any(keyword in user_input.lower() for keyword in [\"ملک\", \"آگهی\", \"سایت\", \"دلتا\", \"محله\", \"مشاور\", \"آژانس\", \"خطا\", \"مجاز\", \"تعداد\"]):\n",
        "                            return connect_to_support.run(tool_input={\"query\": user_input})\n",
        "                    return result\n",
        "                elif tool_name == \"connect_to_support\":\n",
        "                    return connect_to_support.run(tool_input=tool_args)\n",
        "                return \"نمی‌توانم پاسخ این سوال را بدهم\"\n",
        "            except Exception as e:\n",
        "                print(f\"Tool execution error from content: {str(e)}\")\n",
        "                if any(keyword in user_input.lower() for keyword in [\"ملک\", \"آگهی\", \"سایت\", \"دلتا\", \"محله\", \"مشاور\", \"آژانس\", \"خطا\", \"مجاز\", \"تعداد\"]):\n",
        "                    return connect_to_support.run(tool_input={\"query\": user_input})\n",
        "                return \"نمی‌توانم پاسخ این سوال را بدهم\"\n",
        "\n",
        "    if not any(keyword in user_input.lower() for keyword in [\"ملک\", \"آگهی\", \"سایت\", \"دلتا\", \"محله\", \"مشاور\", \"آژانس\", \"خطا\", \"مجاز\", \"تعداد\", \"بخرم\", \"بفروشم\", \"اجاره\"]):\n",
        "        return \"نمی‌توانم پاسخ این سوال را بدهم\"\n",
        "\n",
        "    return response.content if response.content else \"نمی‌توانم پاسخ این سوال را بدهم\""
      ],
      "metadata": {
        "id": "F4sGIPhL7mou"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "input = gr.Textbox(label=\"سوال خود را درباره خرید، فروش، یا اجاره ملک بپرسید\")\n",
        "outputs = gr.Textbox(label=\"\")\n",
        "interface = gr.Interface(\n",
        "    fn=get_answer,\n",
        "    inputs=input,\n",
        "    outputs=outputs,\n",
        "    title=\"دستیار هوشمند دلتا\",\n",
        "    clear_btn=\"پاک کردن\",\n",
        "    allow_flagging=\"never\",\n",
        "    theme=\"dark\"\n",
        ")\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "axl6CADQ4Gxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "aec4f249-7d64-4c2c-adc0-ac958ab939de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1116: UserWarning: Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-681b3f43-0e1922512f5fab153695310e;ffe08f21-c2a3-4d17-ae64-2e2f98ef26a9)\n",
            "\n",
            "Sorry, we can't find the page you are looking for.\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b8e15875667af2b71.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b8e15875667af2b71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}